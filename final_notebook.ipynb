{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":127593,"databundleVersionId":15603876,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport tensorflow as tf\nimport segmentation_models as sm\nimport albumentations as A\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BASE_PATH = '/kaggle/input/terra-seg-rugged-terrain-segmentation/offroad-seg-kaggle'\nTRAIN_IMG_DIR = os.path.join(BASE_PATH, 'train_images')\nTRAIN_MASK_DIR = os.path.join(BASE_PATH, 'train_masks')\nTEST_IMG_DIR = os.path.join(BASE_PATH, 'test_images_padded')\n\nIMG_HEIGHT = 256\nIMG_WIDTH = 256\nBATCH_SIZE = 16\nEPOCHS = 15\nBACKBONE = 'resnet34'\n\npreprocess_input = sm.get_preprocessing(BACKBONE)\n\nprint(\"Configuration Set\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TerraSegGenerator(tf.keras.utils.Sequence):\n    def __init__(self, image_ids, img_dir, mask_dir=None, batch_size=16, \n                 img_size=(256, 256), is_train=True, augment=False):\n        self.image_ids = image_ids\n        self.img_dir = img_dir\n        self.mask_dir = mask_dir\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.is_train = is_train\n        self.augment = augment\n        \n        self.augmentation = A.Compose([\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.2),\n            A.RandomRotate90(p=0.5),\n            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5),\n            A.OneOf([\n                A.RandomBrightnessContrast(p=1),\n                A.HueSaturationValue(p=1),\n            ], p=0.3),\n        ])\n\n    def __len__(self):\n        return int(np.ceil(len(self.image_ids) / self.batch_size))\n\n    def __getitem__(self, index):\n        batch_ids = self.image_ids[index * self.batch_size : (index + 1) * self.batch_size]\n        images, masks = [], []\n        \n        for img_id in batch_ids:\n            img_path = os.path.join(self.img_dir, img_id)\n            img = cv2.imread(img_path)\n            if img is None: continue\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, self.img_size)\n            \n            if self.is_train:\n                mask_path = os.path.join(self.mask_dir, img_id) \n                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n                mask = cv2.resize(mask, self.img_size, interpolation=cv2.INTER_NEAREST)\n                mask = (mask > 0).astype(np.float32)\n\n                if self.augment:\n                    augmented = self.augmentation(image=img, mask=mask)\n                    img, mask = augmented['image'], augmented['mask']\n                \n                masks.append(np.expand_dims(mask, axis=-1))\n            \n            img = preprocess_input(img)\n            images.append(img)\n        \n        if self.is_train:\n            return np.array(images).astype(np.float32), np.array(masks).astype(np.float32)\n        else:\n            return np.array(images).astype(np.float32)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_ids = [f for f in os.listdir(TRAIN_IMG_DIR) if f.endswith(('.png', '.jpg'))]\ntrain_ids, val_ids = train_test_split(all_ids, test_size=0.2, random_state=42)\n\ntrain_gen = TerraSegGenerator(train_ids, TRAIN_IMG_DIR, TRAIN_MASK_DIR, BATCH_SIZE, (IMG_HEIGHT, IMG_WIDTH), is_train=True, augment=True)\nval_gen = TerraSegGenerator(val_ids, TRAIN_IMG_DIR, TRAIN_MASK_DIR, BATCH_SIZE, (IMG_HEIGHT, IMG_WIDTH), is_train=True, augment=False)\n\nmodel = sm.Unet(BACKBONE, encoder_weights='imagenet', classes=1, activation='sigmoid')\n\nmodel.compile(\n    optimizer=Adam(learning_rate=0.0001),\n    loss=sm.losses.bce_jaccard_loss,\n    metrics=[sm.metrics.iou_score]\n)\n\ncallbacks = [\n    ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_iou_score', mode='max', verbose=1),\n    ReduceLROnPlateau(monitor='val_iou_score', factor=0.5, patience=3, min_lr=1e-6, verbose=1, mode='max'),\n    EarlyStopping(monitor='val_iou_score', patience=8, restore_best_weights=True, verbose=1, mode='max')\n]\n\nprint(\"Starting Training\")\nhistory = model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=EPOCHS,\n    callbacks=callbacks\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def rle_encode(img):\n    pixels = img.flatten(order='F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\nprint(\"\\nGenerating Submission\")\nif os.path.exists('best_model.keras'):\n    model.load_weights('best_model.keras')\n\ntest_ids = sorted([f for f in os.listdir(TEST_IMG_DIR) if f.endswith(('.png', '.jpg'))])\nsubmission_data = []\n\nfor img_id in tqdm(test_ids):\n    path = os.path.join(TEST_IMG_DIR, img_id)\n    img = cv2.imread(path)\n    if img is None: continue\n    \n    orig_h, orig_w = img.shape[:2]\n    \n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img_resized = cv2.resize(img_rgb, (IMG_WIDTH, IMG_HEIGHT))\n    img_batch = preprocess_input(np.array([img_resized], dtype=np.float32))\n    \n    pred_mask = model.predict(img_batch, verbose=0)[0]\n    \n    pred_binary = (pred_mask > 0.5).astype(np.uint8)\n    final_mask = cv2.resize(pred_binary, (orig_w, orig_h), interpolation=cv2.INTER_NEAREST)\n    \n    rle = rle_encode(final_mask)\n    clean_id = img_id.split('.')[0] \n    submission_data.append([clean_id, rle])\n\ndf_sub = pd.DataFrame(submission_data, columns=['image_id', 'encoded_pixels'])\ndf_sub.to_csv('submission.csv', index=False)\nprint(\"\\n'submission.csv' generated\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}