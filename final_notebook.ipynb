{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":127593,"databundleVersionId":15603876,"sourceType":"competition"}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install segmentation-models -q\n\nimport os\nos.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport tensorflow as tf\nimport segmentation_models as sm\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\n\nBASE_PATH = '/kaggle/input/terra-seg-rugged-terrain-segmentation/offroad-seg-kaggle'\nTRAIN_IMG_DIR = os.path.join(BASE_PATH, 'train_images')\nTRAIN_MASK_DIR = os.path.join(BASE_PATH, 'train_masks')\nTEST_IMG_DIR = os.path.join(BASE_PATH, 'test_images_padded')\n\nIMG_HEIGHT = 256\nIMG_WIDTH = 256\nBATCH_SIZE = 16\nEPOCHS = 3\nBACKBONE = 'resnet34'\n\npreprocess_input = sm.get_preprocessing(BACKBONE)\n\nprint(\"Configuration Set.\")\n\nclass TerraSegGenerator(tf.keras.utils.Sequence):\n    def __init__(self, image_ids, img_dir, mask_dir=None, batch_size=16, img_size=(256, 256), is_train=True):\n        self.image_ids = image_ids\n        self.img_dir = img_dir\n        self.mask_dir = mask_dir\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.is_train = is_train\n\n    def __len__(self):\n        return int(np.ceil(len(self.image_ids) / self.batch_size))\n\n    def __getitem__(self, index):\n        batch_ids = self.image_ids[index * self.batch_size : (index + 1) * self.batch_size]\n        \n        images = []\n        masks = []\n        \n        for img_id in batch_ids:\n            img_path = os.path.join(self.img_dir, img_id)\n            img = cv2.imread(img_path)\n            img = cv2.resize(img, self.img_size)\n            \n            img = preprocess_input(img)\n            images.append(img)\n            \n            if self.is_train:\n                mask_path = os.path.join(self.mask_dir, img_id) \n                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n                \n                mask = cv2.resize(mask, self.img_size, interpolation=cv2.INTER_NEAREST)\n                \n                mask = (mask > 0).astype(np.float32)\n                \n                mask = np.expand_dims(mask, axis=-1)\n                masks.append(mask)\n        \n        if self.is_train:\n            return np.array(images).astype(np.float32), np.array(masks).astype(np.float32)\n        else:\n            return np.array(images).astype(np.float32)\n\nall_ids = os.listdir(TRAIN_IMG_DIR)\ntrain_ids, val_ids = train_test_split(all_ids, test_size=0.2, random_state=42)\n\ntrain_gen = TerraSegGenerator(train_ids, TRAIN_IMG_DIR, TRAIN_MASK_DIR, BATCH_SIZE, (IMG_HEIGHT, IMG_WIDTH), is_train=True)\nval_gen = TerraSegGenerator(val_ids, TRAIN_IMG_DIR, TRAIN_MASK_DIR, BATCH_SIZE, (IMG_HEIGHT, IMG_WIDTH), is_train=True)\n\nmodel = sm.Unet(BACKBONE, encoder_weights='imagenet', classes=1, activation='sigmoid')\n\ncallbacks = [\n    ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_iou_score', mode='max', verbose=1),\n    ReduceLROnPlateau(monitor='val_iou_score', factor=0.5, patience=3, min_lr=1e-6, verbose=1, mode='max'),\n    EarlyStopping(monitor='val_iou_score', patience=8, restore_best_weights=True, verbose=1, mode='max')\n]\n\nmodel.compile(\n    optimizer=Adam(learning_rate=0.0001),\n    loss=sm.losses.bce_jaccard_loss,\n    metrics=[sm.metrics.iou_score]\n)\n\nhistory = model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=EPOCHS,\n    callbacks=callbacks\n)\n\nprint(\"\\nGenerating Submission\")\n\ndef rle_encode(img):\n    pixels = img.flatten(order='F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\nif os.path.exists('best_model.keras'):\n    print(\"Loading Model\")\n    model.load_weights('best_model.keras')\nelse:\n    print(\"Error\")\n\ntest_ids = sorted(os.listdir(TEST_IMG_DIR))\nsubmission_data = []\n\nprint(\"Processing\")\n\nfor img_id in tqdm(test_ids):\n    path = os.path.join(TEST_IMG_DIR, img_id)\n    img = cv2.imread(path)\n    if img is None: continue\n        \n    orig_h, orig_w = img.shape[:2]\n    \n=    img_resized = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n    img_batch = preprocess_input(np.array([img_resized], dtype=np.float32))\n    \n    pred_batch = model.predict(img_batch, verbose=0)\n    pred_mask = pred_batch[0]\n    \n    pred_binary = (pred_mask > 0.5).astype(np.uint8)\n    final_mask = cv2.resize(pred_binary, (orig_w, orig_h), interpolation=cv2.INTER_NEAREST)\n    \n    rle = rle_encode(final_mask)\n    clean_id = img_id.replace('.png', '') \n    \n    submission_data.append([clean_id, rle])\n\ndf_sub = pd.DataFrame(submission_data, columns=['image_id', 'encoded_pixels'])\ndf_sub.to_csv('submission.csv', index=False)\n\nprint(\"\\nsubmission.csv generated with\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T14:35:38.707290Z","iopub.execute_input":"2026-02-08T14:35:38.708069Z","iopub.status.idle":"2026-02-08T14:42:19.238081Z","shell.execute_reply.started":"2026-02-08T14:35:38.708037Z","shell.execute_reply":"2026-02-08T14:42:19.237287Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hSegmentation Models: using `tf.keras` framework.\nâœ… Configuration Set. Training on: /kaggle/input/terra-seg-rugged-terrain-segmentation/offroad-seg-kaggle/train_images\nDownloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet34_imagenet_1000_no_top.h5\n\u001b[1m85521592/85521592\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nğŸš€ Starting Training...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\n\u001b[1m159/159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - iou_score: 0.5701 - loss: 1.0085\nEpoch 1: val_iou_score improved from -inf to 0.67832, saving model to best_model.keras\n\u001b[1m159/159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 625ms/step - iou_score: 0.5706 - loss: 1.0070 - val_iou_score: 0.6783 - val_loss: 0.7228 - learning_rate: 1.0000e-04\nEpoch 2/3\n\u001b[1m159/159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - iou_score: 0.7972 - loss: 0.4405\nEpoch 2: val_iou_score improved from 0.67832 to 0.82715, saving model to best_model.keras\n\u001b[1m159/159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 504ms/step - iou_score: 0.7973 - loss: 0.4403 - val_iou_score: 0.8272 - val_loss: 0.3710 - learning_rate: 1.0000e-04\nEpoch 3/3\n\u001b[1m159/159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - iou_score: 0.8629 - loss: 0.3013\nEpoch 3: val_iou_score improved from 0.82715 to 0.89126, saving model to best_model.keras\n\u001b[1m159/159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 464ms/step - iou_score: 0.8630 - loss: 0.3011 - val_iou_score: 0.8913 - val_loss: 0.2411 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 3.\n\nğŸ” Generating Submission...\nâœ… Loading best_model.keras\nğŸš€ Processing 1002 test images...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1002/1002 [01:35<00:00, 10.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nğŸ‰ DONE! 'submission.csv' generated with 1002 rows.\nSample IDs: ['0001', '0002', '0003', '0004', '0005']\n","output_type":"stream"}],"execution_count":8}]}